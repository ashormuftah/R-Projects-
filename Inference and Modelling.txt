Inference and ModellingParameters --> are descriptive measures of an entire population that may be used as the inputs for a probability distribution function to generate distribution curves. They are fixed constants, that is, they do not vary like variables. However, their values are usually unknown because it is infeasible to measure an entire population.Estimate --> is a summary of the observed data that we think is informative about the parameter of interest. The Central Limit Theorem --> states that the sampling distribution of the sample means approaches a normal distribution as the sample size gets larger Ñ no matter what the shape of the population distribution.confidence interval (CI) --> is a type of interval estimate, computed from the statistics of the observed data, that might contain the true value of an unknown population parameter. The interval has an associated confidence level that, loosely speaking, quantifies the level of confidence that the parameter lies in the interval.p-value --> helps you determine the significance of your results. The p-value is a number between 0 and 1 and interpreted in the following way: A small p-value (typically ² 0.05) indicates strong evidence against the null hypothesis, so you reject the null hypothesis.BayesÕ theorem --> describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For example, if cancer is related to age, then, using BayesÕ theorem, a personÕs age can be used to more accurately assess the probability that they have cancer, compared to the assessment of the probability of cancer made without knowledge of the person's age.Linear regression -->  is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).# The correlation coefficient is a summary of the trend between two variables.Bivariate normal distribution --> is made up of two independent random variables. The two variables in a bivariate normal are both are normally distributed, and they have a normal distribution when both are added together. Whereas, the ÒregularÓ normal distribution has only one random variable.Multivariate regression --> is a technique that estimates a single regression model with more than one outcome variable. When there is more than one predictor variable in a multivariate regression model, the model is a multivariate multiple regression.Lm() --> is used to fit linear models. It can be used to carry out regression, single stratum analysis of variance and analysis of covariance. The function do() --> it does anything, this is a general purpose complement to the specialised manipulation functions filter(), select(), mutate(), summarise() and arrange(). You can use do() to perform arbitrary computation, returning either a data frame or arbitrary objects which will be stored in a list. This is particularly useful when working with models: you can fit models per group with do() and then flexibly extract components with either another do() or summarise(). It understands a group Tibbles and always returns a data frame. Tibbles  --> are a modern take on data frames. They keep the features that have stood the test of time and drop the features that used to be convenient but are now frustrating (i.e. converting character vectors to factors).