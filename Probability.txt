ProbabilityIn probability theory and statistics, a probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment. In more technical terms, the probability distribution is a description of a random phenomenon in terms of the probabilities of events. For instance, if the random variable X is used to denote the outcome of a coin toss ("the experiment"), then the probability distribution of X would take the value 0.5 for X = heads, and 0.5 for X = tails (assuming the coin is fair). Examples of random phenomena can include the results of an experiment or survey. A discrete probability distribution is a probability distribution characterized by a probability mass function. Thus, the distribution of a random variable X is discrete, and X is called a discrete random variableMonte Carlo methods are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. Their essential idea is using randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integration, and generating draws from a probability distribution.Sampling without replacement --> it is when you take two ball without returning the first ball to the box. To calculate the probability of choosing a ball that is not cyan after one cyan ball has been removed from the box, and the probability of the two sequential actions occuring: use the following code; p_1 <- cyan / (cyan + magenta + yellow)# the probability of choosing a cyan ball from the box on the first pick. p_2 <- 1 - (cyan - 1) / ((cyan + magenta + yellow) - 1)# the probability of not choosing a cyan ball on the second pick without replacement.p_1 * p_2# the probability that the first draw is cyan and the second draw is not cyanNOTE: if the cyan ball was replaced into the box, the code will look like this;p_2 <- 1 - (cyan ) / (cyan + magenta + yellow))Combination --> focuses on the selection of objects without regard to the order in which they are selected. Permutation --> in contrast, focuses on the arrangement of objects with regard to the order in which they are arranged.sapply --> is a user-friendly version and wrapper of lapply by default returning a vector, matrix or, if simplify = "array" , an array if appropriate, by applying simplify2array() . sapply(x, f, simplify = FALSE, USE.NAMES = FALSE) is the same as lapply(x, f).Independence --> the concept extends to dealing with collections of more than two events or random variables, in which case the events are pairwise independent if each pair are independent of each other, and the events are mutually independent if each event is independent of each other combination of events.# if you roll a die 6 times, and you want to see how many times that the number 6 does not appear, use the following code;Rolling_die = 1- (1/6) # the probability of not seeing a 6 on a single roll.Rolling_die^6# the probability of not seeing a 6 on six rolls. NOTE: if you want to see how many times that the number 6 does appear, use the following code;Rolling_die = (1/6) Rolling_die^6# Imagine you are finding the probability of Swansea team winning Manchester City team, knowing that Manchester City have 80% chance to win, and they will be playing 7 games, and of course if Man city wins 4 times in a raw they will win overall. So now you need to find out what is the chance of man city wins the first 4 games, and then find the chance that Swansea wins at least one game of these 4 games. You can do that by using the following code;ManCity_wins_4 = 0.8^4# man city wins the 4 games considering that they have an 80% chance to win.1 - ManCity_wins_4# the chance of Swansea wining at least one game of 4 games. These results can be confirmed by using the Monte Carlo stimulation method (using a 10000 simulations). First, we need to create a code line that stimulate 4 random games where Swansea can either lose or wins (each game is independent of other games), and runing the Monte Carlo simulation 10,000 times.  This can be done by the following code; simulated_games = sample(c("lose","win"), 4, replace = TRUE, prob = c(0.8, 0.4))         B <- 10000Then, we need to create an object called ÔSwansea_winsÕ that first replicate the simulated_games and B codes, then, tallies the number of simulated series that contain at least one win for Swansea. This can be done by the following code; swansea_wins = replicate(B, {  simulated_games <- sample(c("lose","win"), 4, replace = TRUE, prob = c(0.8, 0.2))  any(simulated_games=="win")})Finally, we can calculate the frequency out of B iterations that the Swansea won at least one game, by just printing mean(swansea_wins).Imagine if Man city and Barcelona are playing a seven game championship series. The first to win four games wins the series. The teams are equally good, so they each have a 50-50 chance of winning each game. Say that Man city lost in their first game, and you want to find the probability that they win the whole series. You can achieve this by the following code;n = 6# Assigning the variable 'n' as the number of remaining games (6).l =list(0:1)# Assigning the variable 'l' to a list of possible game outcomes, where 0 indicates a loss and 1 indicates a win for the Man city. list is a function to create a list of game outcomes.possibilities = expand.grid(rep(l, n))# Creating a data frame named 'possibilities' that contains all possible outcomes for the remaining games. expand.grid is a function that creates a data frame containing all the possibilities for outcomes of the remaining games. results = rowSums(possibilities)>=4# Creating a vector named 'results' that indicates whether each row in the data frame 'possibilities' contains enough wins for the Man city to win the series. rowSums is a function that identifie which combinations of game outcomes result in the Man city winning the number of games necessary to win the series.mean(results)# Calculating the proportion of 'results' in which the Man city win the series. A continuous probability distribution describes the probabilities of the possible values of a continuous random variable. A continuous random variable is a random variable with a set of possible values (known as the range) that is infinite and uncountable.# Say that you are gambling, and you have to choose between 38 balls (18 red, 2 green, and 18 black), but if you bet 1£ of the green ball you win 17£. You can calculate the probability of winning the green as follows; green <- 2black <- 18red <- 18p_green <- green / (green+black+red)p_not_green = 1 Ð p_greenexpected_outcome = 17*p_green + -1*p_not_green The standard error --> of a random variable, tells us the difference between a random variable and its expected value.# to calculate a random variable (X) of the gambling example, you can do the following; X = sample(c(17, -1), 1, prob = (p_green, p_not_green)). # therefore, to calculate the standard error, abs(17 - (-1))*sqrt(p_green*p_not_green)# as with the given two possible outcomes (17,-1), with the probability of -1 equals p_green, the standard error of the random variable can be calculated by the following equation; |17 Ð (-1)| * Ã(p_(_green)*p_not_green)